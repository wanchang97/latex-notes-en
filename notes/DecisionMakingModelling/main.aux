\relax 
\abx@aux@refcontext{none/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{ii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Dedication}{iii}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Reninforcement Learning(RL)}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:RL}{{1}{2}{Reninforcement Learning(RL)}{chapter.1}{}}
\newlabel{chap:RL@cref}{{[chapter][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Markov Decision Process}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Basic Formulation and terminology}{2}{subsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Sequential Probabilistic Graphical Model of Markovian Decision Process}}{2}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: MDPDiagramSequential}{{1.1}{2}{Sequential Probabilistic Graphical Model of Markovian Decision Process}{figure.caption.8}{}}
\newlabel{fig: MDPDiagramSequential@cref}{{[figure][1][1]1.1}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{State space $\mathds  {S}$ }{3}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Action space $\mathds  {A}$}{3}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Policy $\pi (a|s)$ }{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{State Transition Model $\mathbf  {T}$}{4}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reward model $\mathbf  {R}$ (negative cost function)}{4}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The cumulative weighted total return $ U^{\pi }(s_t,a_t,\cdots  ,s_T,a_T) $}{4}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Expected cumulative weighted total return $J^{\pi }$}{4}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State-Action Value function $Q^{\pi }(s_t,a_t)$}{5}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State Value Function $V^{\pi }(s_t)$}{5}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $Q^{\star }(s_t,a_t)$}{5}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Value Function $V^{\star }(s_t)$}{6}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bellman Equation for State-Action Value Function $Q^{\pi }(s_t,a_t)$}{6}{section*.20}\protected@file@percent }
\newlabel{eqn: Bellman Qpi}{{1.8}{6}{Bellman Equation for State-Action Value Function $\Qpi (s_t,a_t)$}{equation.1.1.8}{}}
\newlabel{eqn: Bellman Qpi@cref}{{[subequation][8][1]1.8}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsubsection}{Bellman Equation for State Value Function $V^{\pi }(s_t)$}{7}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Optimal Bellman Equation for State Action Value Function $Q^{\star }(s_t,a_t)$}{8}{section*.22}\protected@file@percent }
\newlabel{eqn: MaxValueOfStateAction}{{1.19}{9}{Optimal Bellman Equation for State Action Value Function $\Qstar (s_t,a_t)$}{equation.1.1.19}{}}
\newlabel{eqn: MaxValueOfStateAction@cref}{{[subequation][19][1]1.19}{[1][8][]9}}
\@writefile{toc}{\contentsline {subsubsection}{Optimal Bellman Equation for State Value Function $V^{\star }(s_t)$}{9}{section*.23}\protected@file@percent }
\newlabel{eqn: MaxValueOfState}{{1.21}{9}{Optimal Bellman Equation for State Value Function $\Vstar (s_t)$}{equation.1.1.21}{}}
\newlabel{eqn: MaxValueOfState@cref}{{[subequation][21][1]1.21}{[1][9][]9}}
\newlabel{eqn:BellmanEqnOptimalValueFunction}{{1.22}{9}{Optimal Bellman Equation for State Value Function $\Vstar (s_t)$}{equation.1.1.22}{}}
\newlabel{eqn:BellmanEqnOptimalValueFunction@cref}{{[subequation][22][1]1.22}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Algorithm to solve a Markov Decision Process}{10}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Value Learning}{10}{subsection.1.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Example of a table estimation for the optimal state-action value function $Q(S,A)$}}{10}{table.caption.24}\protected@file@percent }
\newlabel{table: ExampleOfTableEstimationForQ}{{1.1}{10}{Example of a table estimation for the optimal state-action value function $Q(S,A)$}{table.caption.24}{}}
\newlabel{table: ExampleOfTableEstimationForQ@cref}{{[table][1][1]1.1}{[1][10][]10}}
\newlabel{eqn: GradientL}{{1.24}{11}{Value Learning}{equation.1.1.24}{}}
\newlabel{eqn: GradientL@cref}{{[equation][24][1]1.24}{[1][11][]11}}
\newlabel{eqn:ParameterUpdateQ}{{1.25}{11}{Value Learning}{equation.1.1.25}{}}
\newlabel{eqn:ParameterUpdateQ@cref}{{[equation][25][1]1.25}{[1][11][]11}}
\newlabel{eqn: MonteCarloTarget}{{1.26}{11}{Value Learning}{equation.1.1.26}{}}
\newlabel{eqn: MonteCarloTarget@cref}{{[equation][26][1]1.26}{[1][11][]11}}
\newlabel{eqn: mstepTDtargetQ}{{1.27}{11}{Value Learning}{equation.1.1.27}{}}
\newlabel{eqn: mstepTDtargetQ@cref}{{[equation][27][1]1.27}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Policy Learning}{11}{subsection.1.1.4}\protected@file@percent }
\newlabel{eqn:ParameterUpdateQpi}{{1.29}{11}{Policy Learning}{equation.1.1.29}{}}
\newlabel{eqn:ParameterUpdateQpi@cref}{{[equation][29][1]1.29}{[1][11][]11}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Example of a table estimation for $Q^{\pi }(S,A)$}}{12}{table.caption.25}\protected@file@percent }
\newlabel{table: ExampleOfTableEstimationForQpi}{{1.2}{12}{Example of a table estimation for $Q^{\pi }(S,A)$}{table.caption.25}{}}
\newlabel{table: ExampleOfTableEstimationForQpi@cref}{{[table][2][1]1.2}{[1][11][]12}}
\newlabel{eqn: MonteCarloTargetQpi}{{1.30}{12}{Policy Learning}{equation.1.1.30}{}}
\newlabel{eqn: MonteCarloTargetQpi@cref}{{[equation][30][1]1.30}{[1][11][]12}}
\newlabel{eqn: mstepTDtargetQpi}{{1.31}{12}{Policy Learning}{equation.1.1.31}{}}
\newlabel{eqn: mstepTDtargetQpi@cref}{{[equation][31][1]1.31}{[1][12][]12}}
\newlabel{eqn:ParameterUpdateJ}{{1.34}{12}{Policy Learning}{equation.1.1.34}{}}
\newlabel{eqn:ParameterUpdateJ@cref}{{[equation][34][1]1.34}{[1][12][]12}}
\newlabel{eqn:GradientJ}{{1.35}{12}{Policy Learning}{equation.1.1.35}{}}
\newlabel{eqn:GradientJ@cref}{{[equation][35][1]1.35}{[1][12][]12}}
\abx@aux@cite{0}{info10040122}
\abx@aux@segm{0}{0}{info10040122}
\abx@aux@cite{0}{cybenko1989approximation}
\abx@aux@segm{0}{0}{cybenko1989approximation}
\abx@aux@cite{0}{hornik1989multilayer}
\abx@aux@segm{0}{0}{hornik1989multilayer}
\abx@aux@cite{0}{yarotsky2017error}
\abx@aux@segm{0}{0}{yarotsky2017error}
\abx@aux@cite{0}{cuomo2022scientific}
\abx@aux@segm{0}{0}{cuomo2022scientific}
\newlabel{eqn:GradientREINFORCEwithbaseline}{{1.38}{13}{Policy Learning}{equation.1.1.38}{}}
\newlabel{eqn:GradientREINFORCEwithbaseline@cref}{{[equation][38][1]1.38}{[1][13][]13}}
\newlabel{eqn:ACgradient}{{1.39}{13}{Policy Learning}{equation.1.1.39}{}}
\newlabel{eqn:ACgradient@cref}{{[equation][39][1]1.39}{[1][13][]13}}
\newlabel{eqn:GradientA2C}{{1.42}{13}{Policy Learning}{equation.1.1.42}{}}
\newlabel{eqn:GradientA2C@cref}{{[equation][42][1]1.42}{[1][13][]13}}
\newlabel{eqn:ParameterUpdateJcontinue}{{1.43}{13}{Policy Learning}{equation.1.1.43}{}}
\newlabel{eqn:ParameterUpdateJcontinue@cref}{{[equation][43][1]1.43}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Deep Reinforcement Learning}{13}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Deep Q-Network (DQN)}{14}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Deep Q-Network approximate the Q function for every available action using state as input $Q(s_t,a_t)$}}{14}{figure.caption.26}\protected@file@percent }
\newlabel{fig: NNapproximateQ}{{1.2}{14}{Deep Q-Network approximate the Q function for every available action using state as input $Q(s_t,a_t)$}{figure.caption.26}{}}
\newlabel{fig: NNapproximateQ@cref}{{[figure][2][1]1.2}{[1][14][]14}}
\abx@aux@cite{0}{mnih2013playing}
\abx@aux@segm{0}{0}{mnih2013playing}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Deep Q Network(DQN) Training}}{15}{algocf.1}\protected@file@percent }
\newlabel{alg: DQN}{{1}{15}{Deep Q-Network (DQN)}{algocf.1}{}}
\newlabel{alg: DQN@cref}{{[algorithm][1][]1}{[1][15][]15}}
\@writefile{toc}{\contentsline {subsubsection}{Disadvantages of DQN}{15}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Improve the training algorithm}{16}{section*.28}\protected@file@percent }
\newlabel{eqn: TDtargetofQ-learning}{{1.50}{16}{Improve the training algorithm}{equation.1.2.50}{}}
\newlabel{eqn: TDtargetofQ-learning@cref}{{[equation][50][1]1.50}{[1][16][]16}}
\newlabel{eqn: TDtargetofQ-learningWithTarget}{{1.51}{16}{Improve the training algorithm}{equation.1.2.51}{}}
\newlabel{eqn: TDtargetofQ-learningWithTarget@cref}{{[equation][51][1]1.51}{[1][16][]16}}
\newlabel{eqn: TDtargetofDoubleQlearning}{{1.52}{17}{Improve the training algorithm}{equation.1.2.52}{}}
\newlabel{eqn: TDtargetofDoubleQlearning@cref}{{[equation][52][1]1.52}{[1][16][]17}}
\@writefile{toc}{\contentsline {subsubsection}{Improved the Neural Network Architecture}{17}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Dueling Network architecture}}{18}{figure.caption.30}\protected@file@percent }
\newlabel{fig: Dueling Network approximate Q}{{1.3}{18}{Dueling Network architecture}{figure.caption.30}{}}
\newlabel{fig: Dueling Network approximate Q@cref}{{[figure][3][1]1.3}{[1][17][]18}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Deep Q Network(DQN) with Noisy Net Training}}{18}{algocf.2}\protected@file@percent }
\newlabel{alg: DQNwithNoisyNet}{{2}{18}{Improved the Neural Network Architecture}{algocf.2}{}}
\newlabel{alg: DQNwithNoisyNet@cref}{{[algorithm][2][]2}{[1][17][]18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Deep Policy Gradients}{19}{subsection.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces NN approximates $\pi (a_t|s_t)$}}{19}{figure.caption.31}\protected@file@percent }
\newlabel{fig: NNapproximate Pi}{{1.4}{19}{NN approximates $\pi (a_t|s_t)$}{figure.caption.31}{}}
\newlabel{fig: NNapproximate Pi@cref}{{[figure][4][1]1.4}{[1][19][]19}}
\@writefile{toc}{\contentsline {subsubsection}{Actor-Critic Algorithm}{19}{section*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Actor Critic Neural Network architecture}}{20}{figure.caption.32}\protected@file@percent }
\newlabel{fig: NNapproximate AC}{{1.5}{20}{Actor Critic Neural Network architecture}{figure.caption.32}{}}
\newlabel{fig: NNapproximate AC@cref}{{[figure][5][1]1.5}{[1][19][]20}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Actor-Critic(AC)}}{20}{algocf.3}\protected@file@percent }
\newlabel{alg: AC}{{3}{20}{Actor-Critic Algorithm}{algocf.3}{}}
\newlabel{alg: AC@cref}{{[algorithm][3][]3}{[1][19][]20}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Actor-Critic(AC) with target network}}{21}{algocf.4}\protected@file@percent }
\newlabel{alg: ACwithTargetNetwork}{{4}{21}{Actor-Critic Algorithm}{algocf.4}{}}
\newlabel{alg: ACwithTargetNetwork@cref}{{[algorithm][4][]4}{[1][21][]21}}
\@writefile{toc}{\contentsline {subsubsection}{Advantage Actor-Critic (A2C) Algorithm}{22}{section*.34}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Advantage Actor-Critic(A2C) with target network}}{22}{algocf.5}\protected@file@percent }
\newlabel{alg: A2C}{{5}{22}{Advantage Actor-Critic (A2C) Algorithm}{algocf.5}{}}
\newlabel{alg: A2C@cref}{{[algorithm][5][]5}{[1][21][]22}}
\@writefile{toc}{\contentsline {subsubsection}{Asynchronous Advantage Actor Critic (A3C) Algorithm}{22}{section*.35}\protected@file@percent }
\abx@aux@cite{0}{andriotis2019managing}
\abx@aux@segm{0}{0}{andriotis2019managing}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Multi-agent Actor Critic(MAC)}{23}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Fully cooperative mode}{23}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Deep Centralized Multi-agent Actor Critic (DCMAC)}{23}{section*.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Deep Centralized Multi-agent Actor Critic Neural Network architecture}}{23}{figure.caption.38}\protected@file@percent }
\newlabel{fig: DCMAC}{{1.6}{23}{Deep Centralized Multi-agent Actor Critic Neural Network architecture}{figure.caption.38}{}}
\newlabel{fig: DCMAC@cref}{{[figure][6][1]1.6}{[1][23][]23}}
\abx@aux@cite{0}{andriotis2021deep}
\abx@aux@segm{0}{0}{andriotis2021deep}
\abx@aux@cite{0}{andriotis2023structural}
\abx@aux@segm{0}{0}{andriotis2023structural}
\@writefile{toc}{\contentsline {subsubsection}{Deep Decentralized Multi-agent Actor Critic (DDMAC)}{24}{section*.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Deep Decentralized Multi-agent Actor Critic Neural Network architecture}}{24}{figure.caption.40}\protected@file@percent }
\newlabel{fig: DDMAC}{{1.7}{24}{Deep Decentralized Multi-agent Actor Critic Neural Network architecture}{figure.caption.40}{}}
\newlabel{fig: DDMAC@cref}{{[figure][7][1]1.7}{[1][24][]24}}
\@writefile{toc}{\contentsline {subsubsection}{Hierarchical Resource Allocation and Continuous-control Reinforcement Learning}{24}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Partially Observable Markov Decision Process}{25}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Basic Formulation and terminology}{25}{subsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in State Space}}{25}{figure.caption.42}\protected@file@percent }
\newlabel{fig: POMDPDiagramSequential}{{1.8}{25}{Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in State Space}{figure.caption.42}{}}
\newlabel{fig: POMDPDiagramSequential@cref}{{[figure][8][1]1.8}{[1][25][]25}}
\@writefile{toc}{\contentsline {subsubsection}{Belief Space $\mathbb  {B}$}{26}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Belief Update Rule}{27}{section*.44}\protected@file@percent }
\newlabel{eqn: BeliefUpdate}{{1.73}{27}{Belief Update Rule}{equation.1.3.73}{}}
\newlabel{eqn: BeliefUpdate@cref}{{[equation][73][1]1.73}{[1][27][]27}}
\newlabel{eqn: BeliefUpdateSimplified}{{1.74}{27}{Belief Update Rule}{equation.1.3.74}{}}
\newlabel{eqn: BeliefUpdateSimplified@cref}{{[equation][74][1]1.74}{[1][27][]27}}
\@writefile{toc}{\contentsline {subsubsection}{Belief-MDP}{27}{section*.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in Belief Space}}{28}{figure.caption.46}\protected@file@percent }
\newlabel{fig: BeliefMDPDiagramSequential}{{1.9}{28}{Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in Belief Space}{figure.caption.46}{}}
\newlabel{fig: BeliefMDPDiagramSequential@cref}{{[figure][9][1]1.9}{[1][27][]28}}
\@writefile{toc}{\contentsline {subsubsection}{Observation Model of Belief-MDP $P(o_{t+1}|\mathbf  {b}_t,a_t)$}{28}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{State Transition Model of Belief-MDP $\mathbf  {T}_{belief}$}{28}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reward Model of Belief-MDP $\mathbf  {R}_{belief}$}{29}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The cumulative weighted total return $ U^{\pi }(\mathbf  {b}_t,a_t,\cdots  ,\mathbf  {b}_T,a_T) $}{29}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State-Action Value Function $Q^{\pi }(\mathbf  {b}_t,a_t)$}{29}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State Value Function $V^{\pi }(\mathbf  {b}_t)$}{30}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $Q^{\star }(\mathbf  {b}_t,a_t)$}{30}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Value Function $V^{\star }(\mathbf  {b}_t)$}{30}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $V^{\star }(\mathbf  {b}_t)$}{30}{section*.55}\protected@file@percent }
\newlabel{eqn: MaxValueOfBeliefState}{{1.88}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.88}{}}
\newlabel{eqn: MaxValueOfBeliefState@cref}{{[subequation][88][1]1.88}{[1][31][]31}}
\newlabel{eqn:BellmanEqnOptimalValueFunctionforBeliefState}{{1.89}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.89}{}}
\newlabel{eqn:BellmanEqnOptimalValueFunctionforBeliefState@cref}{{[subequation][89][1]1.89}{[1][31][]31}}
\newlabel{eqn:OptimalValueFunctionAffineHyperplaneRepresentation}{{1.90}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.90}{}}
\newlabel{eqn:OptimalValueFunctionAffineHyperplaneRepresentation@cref}{{[equation][90][1]1.90}{[1][31][]31}}
\abx@aux@cite{0}{johnson2018foundations}
\abx@aux@segm{0}{0}{johnson2018foundations}
\abx@aux@cite{0}{brown2021deeplearning}
\abx@aux@segm{0}{0}{brown2021deeplearning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Algorithm to solve a Partially Observable Markov Decision Process}{32}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Common Implementations}{32}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Recent Advances}{32}{section.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Comparison of traditional methods}}{33}{table.caption.56}\protected@file@percent }
\newlabel{tab:traditional_methods}{{1.3}{33}{Comparison of traditional methods}{table.caption.56}{}}
\newlabel{tab:traditional_methods@cref}{{[table][3][1]1.3}{[1][32][]33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Machine Learning Techniques}{33}{subsection.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Research Gaps}{33}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Active Inference(AIF)}{34}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:AIF}{{2}{34}{Active Inference(AIF)}{chapter.2}{}}
\newlabel{chap:AIF@cref}{{[chapter][2][]2}{[1][34][]34}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Active Inference}{34}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Original POMDP Model}}{34}{figure.caption.57}\protected@file@percent }
\newlabel{fig: OriginalPOMDP}{{2.1}{34}{Original POMDP Model}{figure.caption.57}{}}
\newlabel{fig: OriginalPOMDP@cref}{{[figure][1][2]2.1}{[1][34][]34}}
\abx@aux@cite{0}{sajid2021active}
\abx@aux@segm{0}{0}{sajid2021active}
\abx@aux@cite{0}{sajid2021active}
\abx@aux@segm{0}{0}{sajid2021active}
\abx@aux@cite{0}{lee2019optimization}
\abx@aux@segm{0}{0}{lee2019optimization}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graphical Representation of the Generative Process(based on the true states $s^{\star }$) in the world and the corresponding (internal) generative model (based on probabilistic beliefs random variables $s$) that best explain the outcomes $o$. The outcomes are shared between the generative process and model. \blx@tocontentsinit {0}\cite {sajid2021active}}}{35}{figure.caption.58}\protected@file@percent }
\newlabel{fig: GenerativeProcessAndGenerativeModel}{{2.2}{35}{Graphical Representation of the Generative Process(based on the true states $s^{\star }$) in the world and the corresponding (internal) generative model (based on probabilistic beliefs random variables $s$) that best explain the outcomes $o$. The outcomes are shared between the generative process and model. \cite {sajid2021active}}{figure.caption.58}{}}
\newlabel{fig: GenerativeProcessAndGenerativeModel@cref}{{[figure][2][2]2.2}{[1][35][]35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Data Collection}{35}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Algorithm Design}{35}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Experimental Setup}{35}{section.2.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Proposed Optimization Algorithm}}{36}{algocf.6}\protected@file@percent }
\newlabel{alg:proposed}{{6}{36}{Algorithm Design}{algocf.6}{}}
\newlabel{alg:proposed@cref}{{[algorithm][6][]6}{[1][35][]36}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Structural Integration Management}{37}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:StructuralIntegrationManagement}{{3}{37}{Structural Integration Management}{chapter.3}{}}
\newlabel{chap:StructuralIntegrationManagement@cref}{{[chapter][3][]3}{[1][37][]37}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}simple example}{37}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Problem Formulation: 1D Beam with deteriorating stiffness}{37}{subsection.3.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Configuration of Steel Truss Bridge Structure}}{37}{table.caption.62}\protected@file@percent }
\newlabel{table: ConfigurationBeam}{{3.1}{37}{Configuration of Steel Truss Bridge Structure}{table.caption.62}{}}
\newlabel{table: ConfigurationBeam@cref}{{[table][1][3]3.1}{[1][37][]37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Flowchart diagram}}{38}{figure.caption.60}\protected@file@percent }
\newlabel{fig: flowchart}{{3.1}{38}{Flowchart diagram}{figure.caption.60}{}}
\newlabel{fig: flowchart@cref}{{[figure][1][3]3.1}{[1][37][]38}}
\abx@aux@cite{0}{ellingwood2005risk}
\abx@aux@segm{0}{0}{ellingwood2005risk}
\abx@aux@cite{0}{van2009survey}
\abx@aux@segm{0}{0}{van2009survey}
\abx@aux@cite{0}{sanchez2016reliability}
\abx@aux@segm{0}{0}{sanchez2016reliability}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Geometrical Property of Steel Truss Bridge Structure}}{39}{figure.caption.61}\protected@file@percent }
\newlabel{fig: 1D beam example}{{3.2}{39}{Geometrical Property of Steel Truss Bridge Structure}{figure.caption.61}{}}
\newlabel{fig: 1D beam example@cref}{{[figure][2][3]3.2}{[1][37][]39}}
\newlabel{eqn: gradualDeteriorationModel1}{{3.1}{39}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.1}{}}
\newlabel{eqn: gradualDeteriorationModel1@cref}{{[equation][1][3]3.1}{[1][39][]39}}
\newlabel{eqn: changeOfgradualDeteriorationModel1}{{3.2}{39}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.2}{}}
\newlabel{eqn: changeOfgradualDeteriorationModel1@cref}{{[equation][2][3]3.2}{[1][39][]39}}
\newlabel{eqn: fSuddenDeteriorationModel1}{{3.3}{39}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.3}{}}
\newlabel{eqn: fSuddenDeteriorationModel1@cref}{{[equation][3][3]3.3}{[1][39][]39}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Gradual deterioration realization plot modeled by a simple rate function}}{40}{figure.caption.63}\protected@file@percent }
\newlabel{fig: gradual deterioration example plot}{{3.3}{40}{Gradual deterioration realization plot modeled by a simple rate function}{figure.caption.63}{}}
\newlabel{fig: gradual deterioration example plot@cref}{{[figure][3][3]3.3}{[1][39][]40}}
\newlabel{eqn: changeOfSuddenDeteriorationModel1}{{3.4}{40}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.4}{}}
\newlabel{eqn: changeOfSuddenDeteriorationModel1@cref}{{[equation][4][3]3.4}{[1][39][]40}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Prior distribution of deterioration model parameters}}{40}{table.caption.65}\protected@file@percent }
\newlabel{table: Prior distribution of deterioration model parameters}{{3.2}{40}{Prior distribution of deterioration model parameters}{table.caption.65}{}}
\newlabel{table: Prior distribution of deterioration model parameters@cref}{{[table][2][3]3.2}{[1][40][]40}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces sudden deterioration realization plot modelled by a CPP process}}{41}{figure.caption.64}\protected@file@percent }
\newlabel{fig: sudden deterioration example plot}{{3.4}{41}{sudden deterioration realization plot modelled by a CPP process}{figure.caption.64}{}}
\newlabel{fig: sudden deterioration example plot@cref}{{[figure][4][3]3.4}{[1][40][]41}}
\newlabel{eqn: staticDisplacementCalculation}{{3.5}{41}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.5}{}}
\newlabel{eqn: staticDisplacementCalculation@cref}{{[equation][5][3]3.5}{[1][41][]41}}
\newlabel{eqn: staticObservationCalculation}{{3.6}{41}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.6}{}}
\newlabel{eqn: staticObservationCalculation@cref}{{[equation][6][3]3.6}{[1][41][]41}}
\newlabel{eqn: dynamicAcc}{{3.7}{41}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.7}{}}
\newlabel{eqn: dynamicAcc@cref}{{[equation][7][3]3.7}{[1][41][]41}}
\newlabel{eqn: dynamicObservationCalculation}{{3.8}{41}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.8}{}}
\newlabel{eqn: dynamicObservationCalculation@cref}{{[equation][8][3]3.8}{[1][41][]41}}
\newlabel{def:AccumulatedDiscountReward}{{3.9}{41}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.9}{}}
\newlabel{def:AccumulatedDiscountReward@cref}{{[equation][9][3]3.9}{[1][41][]41}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Cost Definition in the beam monitoring process}}{42}{table.caption.66}\protected@file@percent }
\newlabel{table: Cost definition in the beam monitoring process}{{3.3}{42}{Cost Definition in the beam monitoring process}{table.caption.66}{}}
\newlabel{table: Cost definition in the beam monitoring process@cref}{{[table][3][3]3.3}{[1][42][]42}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proposed Framework}{42}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendices}{43}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:Appendix}{{A}{43}{Appendices}{appendix.A}{}}
\newlabel{chap:Appendix@cref}{{[appendix][1][2147483647]A}{[1][43][]43}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Probability Basis}{43}{section.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Random Variables}{43}{subsection.A.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Extreme Value (EV) distributions}{43}{section*.67}\protected@file@percent }
\newlabel{eqn:CDFofXmin}{{A.1}{43}{Extreme Value (EV) distributions}{equation.A.1.1}{}}
\newlabel{eqn:CDFofXmin@cref}{{[equation][1][2147483647,1]A.1}{[1][43][]43}}
\newlabel{eqn:PDFofXmin}{{A.6}{43}{Extreme Value (EV) distributions}{equation.A.1.6}{}}
\newlabel{eqn:PDFofXmin@cref}{{[equation][6][2147483647,1]A.6}{[1][43][]43}}
\newlabel{eqn:CDFofXmax}{{A.8}{44}{Extreme Value (EV) distributions}{equation.A.1.8}{}}
\newlabel{eqn:CDFofXmax@cref}{{[equation][8][2147483647,1]A.8}{[1][43][]44}}
\newlabel{eqn:PDFofXmax}{{A.12}{44}{Extreme Value (EV) distributions}{equation.A.1.12}{}}
\newlabel{eqn:PDFofXmax@cref}{{[equation][12][2147483647,1]A.12}{[1][44][]44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Random Process}{44}{subsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bernoulli Process}{44}{section*.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Extreme Value distribution for Maximum}}{45}{figure.caption.68}\protected@file@percent }
\newlabel{fig: EV_distribution_plots}{{A.1}{45}{Extreme Value distribution for Maximum}{figure.caption.68}{}}
\newlabel{fig: EV_distribution_plots@cref}{{[figure][1][2147483647,1]A.1}{[1][44][]45}}
\@writefile{toc}{\contentsline {subsubsection}{Poisson Process}{45}{section*.71}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Bernoulli Process and its associated Probability Distribution}}{46}{figure.caption.70}\protected@file@percent }
\newlabel{fig: Bernoulli Process}{{A.2}{46}{Bernoulli Process and its associated Probability Distribution}{figure.caption.70}{}}
\newlabel{fig: Bernoulli Process@cref}{{[figure][2][2147483647,1]A.2}{[1][44][]46}}
\@writefile{toc}{\contentsline {subsubsection}{Compound Poisson Process}{46}{section*.73}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Poisson Process and its associated Probability Distribution}}{47}{figure.caption.72}\protected@file@percent }
\newlabel{fig: PoissonProcess}{{A.3}{47}{Poisson Process and its associated Probability Distribution}{figure.caption.72}{}}
\newlabel{fig: PoissonProcess@cref}{{[figure][3][2147483647,1]A.3}{[1][45][]47}}
\@writefile{toc}{\contentsline {subsubsection}{Gamma Process}{47}{section*.75}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Compound Process Process and its associated Probability Distribution}}{49}{figure.caption.74}\protected@file@percent }
\newlabel{fig: CompoundPoissonProcess}{{A.4}{49}{Compound Process Process and its associated Probability Distribution}{figure.caption.74}{}}
\newlabel{fig: CompoundPoissonProcess@cref}{{[figure][4][2147483647,1]A.4}{[1][46][]49}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Gamma Process and its associated Probability Distribution}}{50}{figure.caption.76}\protected@file@percent }
\newlabel{fig: GammaProcess}{{A.5}{50}{Gamma Process and its associated Probability Distribution}{figure.caption.76}{}}
\newlabel{fig: GammaProcess@cref}{{[figure][5][2147483647,1]A.5}{[1][48][]50}}
\abx@aux@read@bbl@mdfivesum{D41D8CD98F00B204E9800998ECF8427E}
\abx@aux@read@bblrerun
\gdef \@abspage@last{59}
