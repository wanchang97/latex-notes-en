\relax 
\abx@aux@refcontext{none/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{ii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Dedication}{iii}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Reninforcement Learning(RL)}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:RL}{{1}{2}{Reninforcement Learning(RL)}{chapter.1}{}}
\newlabel{chap:RL@cref}{{[chapter][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Markov Decision Process}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Basic Formulation and terminology}{2}{subsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Sequential Probabilistic Graphical Model of Markovian Decision Process}}{2}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: MDPDiagramSequential}{{1.1}{2}{Sequential Probabilistic Graphical Model of Markovian Decision Process}{figure.caption.8}{}}
\newlabel{fig: MDPDiagramSequential@cref}{{[figure][1][1]1.1}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsubsection}{State space $\mathds  {S}$ }{3}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Action space $\mathds  {A}$}{3}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Policy $\pi (a|s)$ }{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{State Transition Model $\mathbf  {T}$}{4}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reward model $\mathbf  {R}$ (negative cost function)}{4}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The cumulative weighted total return $ U^{\pi }(s_t,a_t,\cdots  ,s_T,a_T) $}{4}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Expected cumulative weighted total return $J^{\pi }$}{4}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State-Action Value function $Q^{\pi }(s_t,a_t)$}{5}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State Value Function $V^{\pi }(s_t)$}{5}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $Q^{\star }(s_t,a_t)$}{5}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Value Function $V^{\star }(s_t)$}{6}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bellman Equation for State-Action Value Function $Q^{\pi }(s_t,a_t)$}{6}{section*.20}\protected@file@percent }
\newlabel{eqn: Bellman Qpi}{{1.8}{6}{Bellman Equation for State-Action Value Function $\Qpi (s_t,a_t)$}{equation.1.1.8}{}}
\newlabel{eqn: Bellman Qpi@cref}{{[subequation][8][1]1.8}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsubsection}{Bellman Equation for State Value Function $V^{\pi }(s_t)$}{7}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Optimal Bellman Equation for State Action Value Function $Q^{\star }(s_t,a_t)$}{8}{section*.22}\protected@file@percent }
\newlabel{eqn: MaxValueOfStateAction}{{1.19}{9}{Optimal Bellman Equation for State Action Value Function $\Qstar (s_t,a_t)$}{equation.1.1.19}{}}
\newlabel{eqn: MaxValueOfStateAction@cref}{{[subequation][19][1]1.19}{[1][8][]9}}
\@writefile{toc}{\contentsline {subsubsection}{Optimal Bellman Equation for State Value Function $V^{\star }(s_t)$}{9}{section*.23}\protected@file@percent }
\newlabel{eqn: MaxValueOfState}{{1.21}{9}{Optimal Bellman Equation for State Value Function $\Vstar (s_t)$}{equation.1.1.21}{}}
\newlabel{eqn: MaxValueOfState@cref}{{[subequation][21][1]1.21}{[1][9][]9}}
\newlabel{eqn:BellmanEqnOptimalValueFunction}{{1.22}{9}{Optimal Bellman Equation for State Value Function $\Vstar (s_t)$}{equation.1.1.22}{}}
\newlabel{eqn:BellmanEqnOptimalValueFunction@cref}{{[subequation][22][1]1.22}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Algorithm to solve a Markov Decision Process}{10}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Value Learning}{10}{subsection.1.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Example of a table estimation for the optimal state-action value function $Q(S,A)$}}{10}{table.caption.24}\protected@file@percent }
\newlabel{table: ExampleOfTableEstimationForQ}{{1.1}{10}{Example of a table estimation for the optimal state-action value function $Q(S,A)$}{table.caption.24}{}}
\newlabel{table: ExampleOfTableEstimationForQ@cref}{{[table][1][1]1.1}{[1][10][]10}}
\newlabel{eqn: GradientL}{{1.24}{11}{Value Learning}{equation.1.1.24}{}}
\newlabel{eqn: GradientL@cref}{{[equation][24][1]1.24}{[1][11][]11}}
\newlabel{eqn:ParameterUpdateQ}{{1.25}{11}{Value Learning}{equation.1.1.25}{}}
\newlabel{eqn:ParameterUpdateQ@cref}{{[equation][25][1]1.25}{[1][11][]11}}
\newlabel{eqn: MonteCarloTarget}{{1.26}{11}{Value Learning}{equation.1.1.26}{}}
\newlabel{eqn: MonteCarloTarget@cref}{{[equation][26][1]1.26}{[1][11][]11}}
\newlabel{eqn: mstepTDtargetQ}{{1.27}{11}{Value Learning}{equation.1.1.27}{}}
\newlabel{eqn: mstepTDtargetQ@cref}{{[equation][27][1]1.27}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Policy Learning}{11}{subsection.1.1.4}\protected@file@percent }
\newlabel{eqn:ParameterUpdateQpi}{{1.29}{11}{Policy Learning}{equation.1.1.29}{}}
\newlabel{eqn:ParameterUpdateQpi@cref}{{[equation][29][1]1.29}{[1][11][]11}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Example of a table estimation for $Q^{\pi }(S,A)$}}{12}{table.caption.25}\protected@file@percent }
\newlabel{table: ExampleOfTableEstimationForQpi}{{1.2}{12}{Example of a table estimation for $Q^{\pi }(S,A)$}{table.caption.25}{}}
\newlabel{table: ExampleOfTableEstimationForQpi@cref}{{[table][2][1]1.2}{[1][11][]12}}
\newlabel{eqn: MonteCarloTargetQpi}{{1.30}{12}{Policy Learning}{equation.1.1.30}{}}
\newlabel{eqn: MonteCarloTargetQpi@cref}{{[equation][30][1]1.30}{[1][11][]12}}
\newlabel{eqn: mstepTDtargetQpi}{{1.31}{12}{Policy Learning}{equation.1.1.31}{}}
\newlabel{eqn: mstepTDtargetQpi@cref}{{[equation][31][1]1.31}{[1][12][]12}}
\newlabel{eqn:ParameterUpdateJ}{{1.34}{12}{Policy Learning}{equation.1.1.34}{}}
\newlabel{eqn:ParameterUpdateJ@cref}{{[equation][34][1]1.34}{[1][12][]12}}
\newlabel{eqn:GradientJ}{{1.35}{12}{Policy Learning}{equation.1.1.35}{}}
\newlabel{eqn:GradientJ@cref}{{[equation][35][1]1.35}{[1][12][]12}}
\abx@aux@cite{0}{info10040122}
\abx@aux@segm{0}{0}{info10040122}
\abx@aux@cite{0}{cybenko1989approximation}
\abx@aux@segm{0}{0}{cybenko1989approximation}
\abx@aux@cite{0}{hornik1989multilayer}
\abx@aux@segm{0}{0}{hornik1989multilayer}
\abx@aux@cite{0}{yarotsky2017error}
\abx@aux@segm{0}{0}{yarotsky2017error}
\abx@aux@cite{0}{cuomo2022scientific}
\abx@aux@segm{0}{0}{cuomo2022scientific}
\newlabel{eqn:GradientREINFORCEwithbaseline}{{1.38}{13}{Policy Learning}{equation.1.1.38}{}}
\newlabel{eqn:GradientREINFORCEwithbaseline@cref}{{[equation][38][1]1.38}{[1][13][]13}}
\newlabel{eqn:ACgradient}{{1.39}{13}{Policy Learning}{equation.1.1.39}{}}
\newlabel{eqn:ACgradient@cref}{{[equation][39][1]1.39}{[1][13][]13}}
\newlabel{eqn:GradientA2C}{{1.42}{13}{Policy Learning}{equation.1.1.42}{}}
\newlabel{eqn:GradientA2C@cref}{{[equation][42][1]1.42}{[1][13][]13}}
\newlabel{eqn:ParameterUpdateJcontinue}{{1.43}{13}{Policy Learning}{equation.1.1.43}{}}
\newlabel{eqn:ParameterUpdateJcontinue@cref}{{[equation][43][1]1.43}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Deep Reinforcement Learning}{13}{section.1.2}\protected@file@percent }
\newlabel{sec: HowToSolveMDP}{{1.2}{13}{Deep Reinforcement Learning}{section.1.2}{}}
\newlabel{sec: HowToSolveMDP@cref}{{[section][2][1]1.2}{[1][13][]13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Deep Q-Network (DQN)}{14}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Deep Q-Network approximate the Q function for every available action using state as input $Q(s_t,a_t)$}}{14}{figure.caption.26}\protected@file@percent }
\newlabel{fig: NNapproximateQ}{{1.2}{14}{Deep Q-Network approximate the Q function for every available action using state as input $Q(s_t,a_t)$}{figure.caption.26}{}}
\newlabel{fig: NNapproximateQ@cref}{{[figure][2][1]1.2}{[1][14][]14}}
\abx@aux@cite{0}{mnih2013playing}
\abx@aux@segm{0}{0}{mnih2013playing}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Deep Q Network(DQN) Training}}{15}{algocf.1}\protected@file@percent }
\newlabel{alg: DQN}{{1}{15}{Deep Q-Network (DQN)}{algocf.1}{}}
\newlabel{alg: DQN@cref}{{[algorithm][1][]1}{[1][15][]15}}
\@writefile{toc}{\contentsline {subsubsection}{Disadvantages of DQN}{15}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Improve the training algorithm}{16}{section*.28}\protected@file@percent }
\newlabel{eqn: TDtargetofQ-learning}{{1.50}{16}{Improve the training algorithm}{equation.1.2.50}{}}
\newlabel{eqn: TDtargetofQ-learning@cref}{{[equation][50][1]1.50}{[1][16][]16}}
\newlabel{eqn: TDtargetofQ-learningWithTarget}{{1.51}{16}{Improve the training algorithm}{equation.1.2.51}{}}
\newlabel{eqn: TDtargetofQ-learningWithTarget@cref}{{[equation][51][1]1.51}{[1][16][]16}}
\newlabel{eqn: TDtargetofDoubleQlearning}{{1.52}{17}{Improve the training algorithm}{equation.1.2.52}{}}
\newlabel{eqn: TDtargetofDoubleQlearning@cref}{{[equation][52][1]1.52}{[1][16][]17}}
\@writefile{toc}{\contentsline {subsubsection}{Improved the Neural Network Architecture}{17}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Dueling Network architecture}}{18}{figure.caption.30}\protected@file@percent }
\newlabel{fig: Dueling Network approximate Q}{{1.3}{18}{Dueling Network architecture}{figure.caption.30}{}}
\newlabel{fig: Dueling Network approximate Q@cref}{{[figure][3][1]1.3}{[1][17][]18}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Deep Q Network(DQN) with Noisy Net Training}}{18}{algocf.2}\protected@file@percent }
\newlabel{alg: DQNwithNoisyNet}{{2}{18}{Improved the Neural Network Architecture}{algocf.2}{}}
\newlabel{alg: DQNwithNoisyNet@cref}{{[algorithm][2][]2}{[1][17][]18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Deep Policy Gradients}{19}{subsection.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces NN approximates $\pi (a_t|s_t)$}}{19}{figure.caption.31}\protected@file@percent }
\newlabel{fig: NNapproximate Pi}{{1.4}{19}{NN approximates $\pi (a_t|s_t)$}{figure.caption.31}{}}
\newlabel{fig: NNapproximate Pi@cref}{{[figure][4][1]1.4}{[1][19][]19}}
\@writefile{toc}{\contentsline {subsubsection}{Actor-Critic Algorithm}{19}{section*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Actor Critic Neural Network architecture}}{20}{figure.caption.32}\protected@file@percent }
\newlabel{fig: NNapproximate AC}{{1.5}{20}{Actor Critic Neural Network architecture}{figure.caption.32}{}}
\newlabel{fig: NNapproximate AC@cref}{{[figure][5][1]1.5}{[1][19][]20}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Actor-Critic(AC)}}{20}{algocf.3}\protected@file@percent }
\newlabel{alg: AC}{{3}{20}{Actor-Critic Algorithm}{algocf.3}{}}
\newlabel{alg: AC@cref}{{[algorithm][3][]3}{[1][19][]20}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Actor-Critic(AC) with target network}}{21}{algocf.4}\protected@file@percent }
\newlabel{alg: ACwithTargetNetwork}{{4}{21}{Actor-Critic Algorithm}{algocf.4}{}}
\newlabel{alg: ACwithTargetNetwork@cref}{{[algorithm][4][]4}{[1][21][]21}}
\@writefile{toc}{\contentsline {subsubsection}{Advantage Actor-Critic (A2C) Algorithm}{22}{section*.34}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Advantage Actor-Critic(A2C) with target network}}{22}{algocf.5}\protected@file@percent }
\newlabel{alg: A2C}{{5}{22}{Advantage Actor-Critic (A2C) Algorithm}{algocf.5}{}}
\newlabel{alg: A2C@cref}{{[algorithm][5][]5}{[1][21][]22}}
\@writefile{toc}{\contentsline {subsubsection}{Asynchronous Advantage Actor Critic (A3C) Algorithm}{22}{section*.35}\protected@file@percent }
\abx@aux@cite{0}{andriotis2019managing}
\abx@aux@segm{0}{0}{andriotis2019managing}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Multi-agent Actor Critic(MAC)}{23}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Fully cooperative mode}{23}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Deep Centralized Multi-agent Actor Critic (DCMAC)}{23}{section*.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Deep Centralized Multi-agent Actor Critic Neural Network architecture}}{23}{figure.caption.38}\protected@file@percent }
\newlabel{fig: DCMAC}{{1.6}{23}{Deep Centralized Multi-agent Actor Critic Neural Network architecture}{figure.caption.38}{}}
\newlabel{fig: DCMAC@cref}{{[figure][6][1]1.6}{[1][23][]23}}
\abx@aux@cite{0}{andriotis2021deep}
\abx@aux@segm{0}{0}{andriotis2021deep}
\abx@aux@cite{0}{andriotis2023structural}
\abx@aux@segm{0}{0}{andriotis2023structural}
\@writefile{toc}{\contentsline {subsubsection}{Deep Decentralized Multi-agent Actor Critic (DDMAC)}{24}{section*.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Deep Decentralized Multi-agent Actor Critic Neural Network architecture}}{24}{figure.caption.40}\protected@file@percent }
\newlabel{fig: DDMAC}{{1.7}{24}{Deep Decentralized Multi-agent Actor Critic Neural Network architecture}{figure.caption.40}{}}
\newlabel{fig: DDMAC@cref}{{[figure][7][1]1.7}{[1][24][]24}}
\@writefile{toc}{\contentsline {subsubsection}{Hierarchical Resource Allocation and Continuous-control Reinforcement Learning}{24}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Partially Observable Markov Decision Process}{25}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Basic Formulation and terminology}{25}{subsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in State Space}}{25}{figure.caption.42}\protected@file@percent }
\newlabel{fig: POMDPDiagramSequential}{{1.8}{25}{Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in State Space}{figure.caption.42}{}}
\newlabel{fig: POMDPDiagramSequential@cref}{{[figure][8][1]1.8}{[1][25][]25}}
\@writefile{toc}{\contentsline {subsubsection}{Belief Space $\mathbb  {B}$}{26}{section*.43}\protected@file@percent }
\newlabel{eq:BeliefDefinition}{{1.69}{26}{Belief Space $\mathbb {B}$}{equation.1.3.69}{}}
\newlabel{eq:BeliefDefinition@cref}{{[equation][69][1]1.69}{[1][26][]26}}
\@writefile{toc}{\contentsline {subsubsection}{Belief Update Rule}{27}{section*.44}\protected@file@percent }
\newlabel{eqn: BeliefUpdate}{{1.73}{27}{Belief Update Rule}{equation.1.3.73}{}}
\newlabel{eqn: BeliefUpdate@cref}{{[equation][73][1]1.73}{[1][27][]27}}
\newlabel{eqn: BeliefUpdateSimplified}{{1.74}{27}{Belief Update Rule}{equation.1.3.74}{}}
\newlabel{eqn: BeliefUpdateSimplified@cref}{{[equation][74][1]1.74}{[1][27][]27}}
\@writefile{toc}{\contentsline {subsubsection}{Belief-MDP}{27}{section*.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in Belief Space}}{28}{figure.caption.46}\protected@file@percent }
\newlabel{fig: BeliefMDPDiagramSequential}{{1.9}{28}{Probabilistic Graphical Model of Partially Observable Markovian Decision Process defined in Belief Space}{figure.caption.46}{}}
\newlabel{fig: BeliefMDPDiagramSequential@cref}{{[figure][9][1]1.9}{[1][27][]28}}
\@writefile{toc}{\contentsline {subsubsection}{Observation Model of Belief-MDP $P(o_{t+1}|\mathbf  {b}_t,a_t)$}{28}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{State Transition Model of Belief-MDP $\mathbf  {T}_{belief}$}{28}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reward Model of Belief-MDP $\mathbf  {R}_{belief}$}{29}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The cumulative weighted total return $ U^{\pi }(\mathbf  {b}_t,a_t,\cdots  ,\mathbf  {b}_T,a_T) $}{29}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State-Action Value Function $Q^{\pi }(\mathbf  {b}_t,a_t)$}{29}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The State Value Function $V^{\pi }(\mathbf  {b}_t)$}{30}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $Q^{\star }(\mathbf  {b}_t,a_t)$}{30}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Value Function $V^{\star }(\mathbf  {b}_t)$}{30}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Optimal State Action Value Function $V^{\star }(\mathbf  {b}_t)$}{30}{section*.55}\protected@file@percent }
\newlabel{eqn: MaxValueOfBeliefState}{{1.88}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.88}{}}
\newlabel{eqn: MaxValueOfBeliefState@cref}{{[subequation][88][1]1.88}{[1][31][]31}}
\newlabel{eqn:BellmanEqnOptimalValueFunctionforBeliefState}{{1.89}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.89}{}}
\newlabel{eqn:BellmanEqnOptimalValueFunctionforBeliefState@cref}{{[subequation][89][1]1.89}{[1][31][]31}}
\newlabel{eqn:OptimalValueFunctionAffineHyperplaneRepresentation}{{1.90}{31}{The Optimal State Action Value Function $\Vstar (\bb _t)$}{equation.1.3.90}{}}
\newlabel{eqn:OptimalValueFunctionAffineHyperplaneRepresentation@cref}{{[equation][90][1]1.90}{[1][31][]31}}
\abx@aux@cite{0}{johnson2018foundations}
\abx@aux@segm{0}{0}{johnson2018foundations}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}How solve a Partially Observable Markov Decision Process}{32}{section.1.4}\protected@file@percent }
\abx@aux@cite{0}{brown2021deeplearning}
\abx@aux@segm{0}{0}{brown2021deeplearning}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Common Implementations}{33}{section.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Comparison of traditional methods}}{33}{table.caption.58}\protected@file@percent }
\newlabel{tab:traditional_methods}{{1.3}{33}{Comparison of traditional methods}{table.caption.58}{}}
\newlabel{tab:traditional_methods@cref}{{[table][3][1]1.3}{[1][33][]33}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Recent Advances}{33}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Machine Learning Techniques}{33}{subsection.1.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Research Gaps}{33}{section.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Deep Q-Network approximate the Q function for every available action using belief as input $Q(\mathbf  {b}_t,a_t)$}}{35}{figure.caption.56}\protected@file@percent }
\newlabel{fig: NNapproximateQBelief}{{1.10}{35}{Deep Q-Network approximate the Q function for every available action using belief as input $Q(\bb _t,a_t)$}{figure.caption.56}{}}
\newlabel{fig: NNapproximateQBelief@cref}{{[figure][10][1]1.10}{[1][32][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Dueling Network architecture}}{36}{figure.caption.57}\protected@file@percent }
\newlabel{fig: Dueling Network approximate QBelief}{{1.11}{36}{Dueling Network architecture}{figure.caption.57}{}}
\newlabel{fig: Dueling Network approximate QBelief@cref}{{[figure][11][1]1.11}{[1][32][]36}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Active Inference(AIF)}{37}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:AIF}{{2}{37}{Active Inference(AIF)}{chapter.2}{}}
\newlabel{chap:AIF@cref}{{[chapter][2][]2}{[1][37][]37}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Active Inference}{37}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Original POMDP Model}}{37}{figure.caption.59}\protected@file@percent }
\newlabel{fig: OriginalPOMDP}{{2.1}{37}{Original POMDP Model}{figure.caption.59}{}}
\newlabel{fig: OriginalPOMDP@cref}{{[figure][1][2]2.1}{[1][37][]37}}
\newlabel{eq:PosteriorBayesianUpdating}{{2.1}{38}{Active Inference}{equation.2.1.1}{}}
\newlabel{eq:PosteriorBayesianUpdating@cref}{{[equation][1][2]2.1}{[1][38][]38}}
\newlabel{eq: KLDivergenceDefinitionOfInformationLoss}{{2.2}{38}{Active Inference}{equation.2.1.2}{}}
\newlabel{eq: KLDivergenceDefinitionOfInformationLoss@cref}{{[equation][2][2]2.2}{[1][38][]38}}
\newlabel{subequation: VFE}{{2.3c}{38}{Active Inference}{equation.2.1.3c}{}}
\newlabel{subequation: VFE@cref}{{[subequation][3][2,3]2.3c}{[1][38][]38}}
\abx@aux@cite{0}{sajid2021active}
\abx@aux@segm{0}{0}{sajid2021active}
\abx@aux@cite{0}{sajid2021active}
\abx@aux@segm{0}{0}{sajid2021active}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The physical meaning of \textbf  {variational free energy} $\mathcal  {F}$}}{39}{table.caption.61}\protected@file@percent }
\newlabel{table: The physical Meaning of variaiton Free Energy}{{2.1}{39}{The physical meaning of \textbf {variational free energy} $\mathcal {F}$}{table.caption.61}{}}
\newlabel{table: The physical Meaning of variaiton Free Energy@cref}{{[table][1][2]2.1}{[1][39][]39}}
\@writefile{toc}{\contentsline {subsubsection}{Variational Free Energy (VFE) $\mathcal  {F}$}{39}{section*.60}\protected@file@percent }
\newlabel{subequation: DivergenceSurprisal}{{2.4b}{39}{Variational Free Energy (VFE) $\mathcal {F}$}{equation.2.1.4b}{}}
\newlabel{subequation: DivergenceSurprisal@cref}{{[subequation][2][2,4]2.4b}{[1][38][]39}}
\newlabel{subequation: ComplexityAccuracy}{{2.4c}{39}{Variational Free Energy (VFE) $\mathcal {F}$}{equation.2.1.4c}{}}
\newlabel{subequation: ComplexityAccuracy@cref}{{[subequation][3][2,4]2.4c}{[1][38][]39}}
\@writefile{toc}{\contentsline {subsubsection}{Expected Free Energy (EFE) $\mathcal  {G}$}{39}{section*.63}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Graphical Representation of the Generative Process(based on the true states $s^{\star }$) in the world and the corresponding (internal) generative model (based on probabilistic beliefs random variables $s$) that best explain the outcomes $o$. The outcomes are shared between the generative process and model. \blx@tocontentsinit {0}\cite {sajid2021active}}}{40}{figure.caption.62}\protected@file@percent }
\newlabel{fig: GenerativeProcessAndGenerativeModel}{{2.2}{40}{Graphical Representation of the Generative Process(based on the true states $s^{\star }$) in the world and the corresponding (internal) generative model (based on probabilistic beliefs random variables $s$) that best explain the outcomes $o$. The outcomes are shared between the generative process and model. \cite {sajid2021active}}{figure.caption.62}{}}
\newlabel{fig: GenerativeProcessAndGenerativeModel@cref}{{[figure][2][2]2.2}{[1][39][]40}}
\newlabel{eqn: EFE}{{2.5}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5}{}}
\newlabel{eqn: EFE@cref}{{[subequation][5][2]2.5}{[1][39][]40}}
\newlabel{subequation:EFE_ProductRuleOfProbability}{{2.5b}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5b}{}}
\newlabel{subequation:EFE_ProductRuleOfProbability@cref}{{[subequation][2][2,5]2.5b}{[1][39][]40}}
\newlabel{subequation:EFE_Q(s|o)}{{2.5d}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5d}{}}
\newlabel{subequation:EFE_Q(s|o)@cref}{{[subequation][4][2,5]2.5d}{[1][39][]40}}
\newlabel{subequation:EFE_P(o|C)}{{2.5e}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5e}{}}
\newlabel{subequation:EFE_P(o|C)@cref}{{[subequation][5][2,5]2.5e}{[1][39][]40}}
\newlabel{subequation:EFE_Q(o|s)}{{2.5f}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5f}{}}
\newlabel{subequation:EFE_Q(o|s)@cref}{{[subequation][6][2,5]2.5f}{[1][39][]40}}
\newlabel{subequation:EFE_P(o|s)}{{2.5g}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5g}{}}
\newlabel{subequation:EFE_P(o|s)@cref}{{[subequation][7][2,5]2.5g}{[1][39][]40}}
\newlabel{subequation:EFE_RiskAmbiguity}{{2.5h}{40}{Expected Free Energy (EFE) $\mathcal {G}$}{equation.2.1.5h}{}}
\newlabel{subequation:EFE_RiskAmbiguity@cref}{{[subequation][8][2,5]2.5h}{[1][39][]40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Data Collection}{41}{subsection.2.1.1}\protected@file@percent }
\abx@aux@cite{0}{lee2019optimization}
\abx@aux@segm{0}{0}{lee2019optimization}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Algorithm Design}{42}{section.2.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Proposed Optimization Algorithm}}{42}{algocf.6}\protected@file@percent }
\newlabel{alg:proposed}{{6}{42}{Algorithm Design}{algocf.6}{}}
\newlabel{alg:proposed@cref}{{[algorithm][6][]6}{[1][42][]42}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Experimental Setup}{42}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Structural Integration Management}{43}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:StructuralIntegrationManagement}{{3}{43}{Structural Integration Management}{chapter.3}{}}
\newlabel{chap:StructuralIntegrationManagement@cref}{{[chapter][3][]3}{[1][43][]43}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}simple example}{43}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Problem Formulation: 1D Beam with deteriorating stiffness}{43}{subsection.3.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Configuration of Steel Truss Bridge Structure}}{43}{table.caption.67}\protected@file@percent }
\newlabel{table: ConfigurationBeam}{{3.1}{43}{Configuration of Steel Truss Bridge Structure}{table.caption.67}{}}
\newlabel{table: ConfigurationBeam@cref}{{[table][1][3]3.1}{[1][43][]43}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Flowchart diagram}}{44}{figure.caption.65}\protected@file@percent }
\newlabel{fig: flowchart}{{3.1}{44}{Flowchart diagram}{figure.caption.65}{}}
\newlabel{fig: flowchart@cref}{{[figure][1][3]3.1}{[1][43][]44}}
\abx@aux@cite{0}{ellingwood2005risk}
\abx@aux@segm{0}{0}{ellingwood2005risk}
\abx@aux@cite{0}{van2009survey}
\abx@aux@segm{0}{0}{van2009survey}
\abx@aux@cite{0}{sanchez2016reliability}
\abx@aux@segm{0}{0}{sanchez2016reliability}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Geometrical Property of Steel Truss Bridge Structure}}{45}{figure.caption.66}\protected@file@percent }
\newlabel{fig: 1D beam example}{{3.2}{45}{Geometrical Property of Steel Truss Bridge Structure}{figure.caption.66}{}}
\newlabel{fig: 1D beam example@cref}{{[figure][2][3]3.2}{[1][43][]45}}
\newlabel{eqn: gradualDeteriorationModel1}{{3.1}{45}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.1}{}}
\newlabel{eqn: gradualDeteriorationModel1@cref}{{[equation][1][3]3.1}{[1][45][]45}}
\newlabel{eqn: changeOfgradualDeteriorationModel1}{{3.2}{45}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.2}{}}
\newlabel{eqn: changeOfgradualDeteriorationModel1@cref}{{[equation][2][3]3.2}{[1][45][]45}}
\newlabel{eqn: fSuddenDeteriorationModel1}{{3.3}{45}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.3}{}}
\newlabel{eqn: fSuddenDeteriorationModel1@cref}{{[equation][3][3]3.3}{[1][45][]45}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Gradual deterioration realization plot modeled by a simple rate function}}{46}{figure.caption.68}\protected@file@percent }
\newlabel{fig: gradual deterioration example plot}{{3.3}{46}{Gradual deterioration realization plot modeled by a simple rate function}{figure.caption.68}{}}
\newlabel{fig: gradual deterioration example plot@cref}{{[figure][3][3]3.3}{[1][45][]46}}
\newlabel{eqn: changeOfSuddenDeteriorationModel1}{{3.4}{46}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.4}{}}
\newlabel{eqn: changeOfSuddenDeteriorationModel1@cref}{{[equation][4][3]3.4}{[1][45][]46}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Prior distribution of deterioration model parameters}}{46}{table.caption.70}\protected@file@percent }
\newlabel{table: Prior distribution of deterioration model parameters}{{3.2}{46}{Prior distribution of deterioration model parameters}{table.caption.70}{}}
\newlabel{table: Prior distribution of deterioration model parameters@cref}{{[table][2][3]3.2}{[1][46][]46}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces sudden deterioration realization plot modelled by a CPP process}}{47}{figure.caption.69}\protected@file@percent }
\newlabel{fig: sudden deterioration example plot}{{3.4}{47}{sudden deterioration realization plot modelled by a CPP process}{figure.caption.69}{}}
\newlabel{fig: sudden deterioration example plot@cref}{{[figure][4][3]3.4}{[1][46][]47}}
\newlabel{eqn: staticDisplacementCalculation}{{3.5}{47}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.5}{}}
\newlabel{eqn: staticDisplacementCalculation@cref}{{[equation][5][3]3.5}{[1][47][]47}}
\newlabel{eqn: staticObservationCalculation}{{3.6}{47}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.6}{}}
\newlabel{eqn: staticObservationCalculation@cref}{{[equation][6][3]3.6}{[1][47][]47}}
\newlabel{eqn: dynamicAcc}{{3.7}{47}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.7}{}}
\newlabel{eqn: dynamicAcc@cref}{{[equation][7][3]3.7}{[1][47][]47}}
\newlabel{eqn: dynamicObservationCalculation}{{3.8}{47}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.8}{}}
\newlabel{eqn: dynamicObservationCalculation@cref}{{[equation][8][3]3.8}{[1][47][]47}}
\newlabel{def:AccumulatedDiscountReward}{{3.9}{47}{Problem Formulation: 1D Beam with deteriorating stiffness}{equation.3.1.9}{}}
\newlabel{def:AccumulatedDiscountReward@cref}{{[equation][9][3]3.9}{[1][47][]47}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Cost Definition in the beam monitoring process}}{48}{table.caption.71}\protected@file@percent }
\newlabel{table: Cost definition in the beam monitoring process}{{3.3}{48}{Cost Definition in the beam monitoring process}{table.caption.71}{}}
\newlabel{table: Cost definition in the beam monitoring process@cref}{{[table][3][3]3.3}{[1][48][]48}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proposed Framework}{48}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Flowchart POMDP diagram}}{49}{figure.caption.72}\protected@file@percent }
\newlabel{fig: flowchartPOMDP}{{3.5}{49}{Flowchart POMDP diagram}{figure.caption.72}{}}
\newlabel{fig: flowchartPOMDP@cref}{{[figure][5][3]3.5}{[1][48][]49}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendices}{50}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:Appendix}{{A}{50}{Appendices}{appendix.A}{}}
\newlabel{chap:Appendix@cref}{{[appendix][1][2147483647]A}{[1][50][]50}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Probability Basis}{50}{section.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Random Variables}{50}{subsection.A.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Extreme Value (EV) distributions}{50}{section*.73}\protected@file@percent }
\newlabel{eqn:CDFofXmin}{{A.1}{50}{Extreme Value (EV) distributions}{equation.A.1.1}{}}
\newlabel{eqn:CDFofXmin@cref}{{[equation][1][2147483647,1]A.1}{[1][50][]50}}
\newlabel{eqn:PDFofXmin}{{A.6}{50}{Extreme Value (EV) distributions}{equation.A.1.6}{}}
\newlabel{eqn:PDFofXmin@cref}{{[equation][6][2147483647,1]A.6}{[1][50][]50}}
\newlabel{eqn:CDFofXmax}{{A.8}{51}{Extreme Value (EV) distributions}{equation.A.1.8}{}}
\newlabel{eqn:CDFofXmax@cref}{{[equation][8][2147483647,1]A.8}{[1][50][]51}}
\newlabel{eqn:PDFofXmax}{{A.12}{51}{Extreme Value (EV) distributions}{equation.A.1.12}{}}
\newlabel{eqn:PDFofXmax@cref}{{[equation][12][2147483647,1]A.12}{[1][51][]51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}Random Process}{51}{subsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bernoulli Process}{51}{section*.75}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Extreme Value distribution for Maximum}}{52}{figure.caption.74}\protected@file@percent }
\newlabel{fig: EV_distribution_plots}{{A.1}{52}{Extreme Value distribution for Maximum}{figure.caption.74}{}}
\newlabel{fig: EV_distribution_plots@cref}{{[figure][1][2147483647,1]A.1}{[1][51][]52}}
\@writefile{toc}{\contentsline {subsubsection}{Poisson Process}{52}{section*.77}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Bernoulli Process and its associated Probability Distribution}}{53}{figure.caption.76}\protected@file@percent }
\newlabel{fig: Bernoulli Process}{{A.2}{53}{Bernoulli Process and its associated Probability Distribution}{figure.caption.76}{}}
\newlabel{fig: Bernoulli Process@cref}{{[figure][2][2147483647,1]A.2}{[1][51][]53}}
\@writefile{toc}{\contentsline {subsubsection}{Compound Poisson Process}{53}{section*.79}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Poisson Process and its associated Probability Distribution}}{54}{figure.caption.78}\protected@file@percent }
\newlabel{fig: PoissonProcess}{{A.3}{54}{Poisson Process and its associated Probability Distribution}{figure.caption.78}{}}
\newlabel{fig: PoissonProcess@cref}{{[figure][3][2147483647,1]A.3}{[1][52][]54}}
\@writefile{toc}{\contentsline {subsubsection}{Gamma Process}{54}{section*.81}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Compound Process Process and its associated Probability Distribution}}{56}{figure.caption.80}\protected@file@percent }
\newlabel{fig: CompoundPoissonProcess}{{A.4}{56}{Compound Process Process and its associated Probability Distribution}{figure.caption.80}{}}
\newlabel{fig: CompoundPoissonProcess@cref}{{[figure][4][2147483647,1]A.4}{[1][53][]56}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Gamma Process and its associated Probability Distribution}}{57}{figure.caption.82}\protected@file@percent }
\newlabel{fig: GammaProcess}{{A.5}{57}{Gamma Process and its associated Probability Distribution}{figure.caption.82}{}}
\newlabel{fig: GammaProcess@cref}{{[figure][5][2147483647,1]A.5}{[1][55][]57}}
\abx@aux@read@bbl@mdfivesum{D41D8CD98F00B204E9800998ECF8427E}
\abx@aux@read@bblrerun
\gdef \@abspage@last{66}
